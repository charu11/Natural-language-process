{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "improving_data_for_sa.ipynb",
      "provenance": [],
      "mount_file_id": "1wsS54V_Ok0eS8MZArE7IsCs7bs3hwK6X",
      "authorship_tag": "ABX9TyOMxNSr3my1uy7gQd1eTXR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charu11/Natural-language-process/blob/nlp/improving_data_for_sa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vq0TPwNiLka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "pos = io.open('/content/drive/My Drive/natural_language_process/positive.txt', encoding='latin-1').read()\n",
        "neg = io.open('/content/drive/My Drive/natural_language_process/negative.txt', encoding='latin-1').read()\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in pos.split('\\n'):\n",
        "  documents.append((i, 'pos'))\n",
        "\n",
        "for i in neg.split('\\n'):\n",
        "  documents.append((i, 'neg'))\n",
        "\n",
        "all_words = []\n",
        "\n",
        "pos_words = word_tokenize(pos)\n",
        "neg_words = word_tokenize(neg)\n",
        "\n",
        "for w in pos_words:\n",
        "  all_words.append(w.lower())\n",
        "\n",
        "for w in neg_words:\n",
        "  all_words.append(w.lower())\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykJJM_xwoEd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "word_features = list(all_words.keys())[:5000]\n",
        "\n",
        "def find_features(document):\n",
        "  words = word_tokenize(document)\n",
        "  features = {}\n",
        "  for w in word_features:\n",
        "    features[w] = (w in words)\n",
        "\n",
        "  return features\n",
        "\n",
        "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
        "random.shuffle(featuresets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7hFrp8corY3",
        "colab_type": "code",
        "outputId": "048cb228-43e3-4fc2-abeb-6241a1632e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "import pickle\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "\n",
        "from nltk.classify import ClassifierI\n",
        "from statistics import mode\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "class VoteClassifier(ClassifierI):\n",
        "    def __init__(self, *classifiers):\n",
        "        self._classifiers = classifiers\n",
        "\n",
        "    def classify(self, features):\n",
        "        votes = []\n",
        "        for c in self._classifiers:\n",
        "            v = c.classify(features)\n",
        "            votes.append(v)\n",
        "        return mode(votes)\n",
        "\n",
        "    def confidence(self, features):\n",
        "        votes = []\n",
        "        for c in self._classifiers:\n",
        "            v = c.classify(features)\n",
        "            votes.append(v)\n",
        "\n",
        "        choice_votes = votes.count(mode(votes))\n",
        "        conf = choice_votes / len(votes)\n",
        "        return conf\n",
        "        \n",
        "pos = io.open('/content/drive/My Drive/natural_language_process/positive.txt', encoding='latin-1').read()\n",
        "neg = io.open('/content/drive/My Drive/natural_language_process/negative.txt', encoding='latin-1').read()\n",
        "\n",
        "for i in pos.split('\\n'):\n",
        "  documents.append((i, 'pos'))\n",
        "\n",
        "for i in neg.split('\\n'):\n",
        "  documents.append((i, 'neg'))\n",
        "\n",
        "all_words = []\n",
        "\n",
        "pos_words = word_tokenize(pos)\n",
        "neg_words = word_tokenize(neg)\n",
        "\n",
        "for w in pos_words:\n",
        "  all_words.append(w.lower())\n",
        "\n",
        "for w in neg_words:\n",
        "  all_words.append(w.lower())\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "\n",
        "word_features = list(all_words.keys())[:5000]\n",
        "\n",
        "def find_features(document):\n",
        "    words = word_tokenize(document)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "\n",
        "    return features\n",
        "\n",
        "#print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
        "\n",
        "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
        "\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "# positive data example:      \n",
        "training_set = featuresets[:10000]\n",
        "testing_set =  featuresets[10000:]\n",
        "\n",
        "##\n",
        "### negative data example:      \n",
        "##training_set = featuresets[100:]\n",
        "##testing_set =  featuresets[:100]\n",
        "\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
        "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
        "classifier.show_most_informative_features(15)\n",
        "\n",
        "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
        "MNB_classifier.train(training_set)\n",
        "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
        "\n",
        "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
        "BernoulliNB_classifier.train(training_set)\n",
        "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
        "\n",
        "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
        "LogisticRegression_classifier.train(training_set)\n",
        "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
        "\n",
        "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
        "SGDClassifier_classifier.train(training_set)\n",
        "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
        "\n",
        "##SVC_classifier = SklearnClassifier(SVC())\n",
        "##SVC_classifier.train(training_set)\n",
        "##print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
        "\n",
        "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
        "LinearSVC_classifier.train(training_set)\n",
        "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
        "\n",
        "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
        "NuSVC_classifier.train(training_set)\n",
        "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
        "\n",
        "\n",
        "voted_classifier = VoteClassifier(\n",
        "                                  NuSVC_classifier,\n",
        "                                  LinearSVC_classifier,\n",
        "                                  MNB_classifier,\n",
        "                                  BernoulliNB_classifier,\n",
        "                                  LogisticRegression_classifier)\n",
        "\n",
        "print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Naive Bayes Algo accuracy percent: 77.52471751412429\n",
            "Most Informative Features\n",
            "               wonderful = True              pos : neg    =     22.6 : 1.0\n",
            "              engrossing = True              pos : neg    =     22.6 : 1.0\n",
            "                captures = True              pos : neg    =     20.6 : 1.0\n",
            "                 lacking = True              neg : pos    =     15.3 : 1.0\n",
            "                    warm = True              pos : neg    =     13.6 : 1.0\n",
            "                intimate = True              pos : neg    =     13.4 : 1.0\n",
            "                  unique = True              pos : neg    =     13.4 : 1.0\n",
            "              unexpected = True              pos : neg    =     13.4 : 1.0\n",
            "                    ride = True              pos : neg    =     13.2 : 1.0\n",
            "                     van = True              neg : pos    =     12.6 : 1.0\n",
            "                touching = True              pos : neg    =     12.2 : 1.0\n",
            "               absorbing = True              pos : neg    =     12.1 : 1.0\n",
            "                   quiet = True              pos : neg    =     12.0 : 1.0\n",
            "                  stupid = True              neg : pos    =     11.6 : 1.0\n",
            "                   roles = True              pos : neg    =     11.5 : 1.0\n",
            "MNB_classifier accuracy percent: 76.73022598870057\n",
            "BernoulliNB_classifier accuracy percent: 77.27754237288136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression_classifier accuracy percent: 80.36723163841808\n",
            "SGDClassifier_classifier accuracy percent: 79.81991525423729\n",
            "LinearSVC_classifier accuracy percent: 81.34710451977402\n",
            "NuSVC_classifier accuracy percent: 85.36370056497175\n",
            "voted_classifier accuracy percent: 82.19456214689266\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}